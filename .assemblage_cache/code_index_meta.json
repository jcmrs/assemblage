[{"path": "assemblage\\code_search.py", "line": 22, "content": "\n\ndef _get_all_code_files():\n    \"\"\"\n    Gets all .py files in the repo, respecting .gitignore.\n    \"\"\"\n    print(\"INFO: Finding all Python files in the repository...\")\n    # Use git to list all tracked python files, which respects .gitignore\n    cmd = [\"git\", \"ls-files\", \"*.py\"]\n    result = subprocess.run(cmd, capture_output=True, text=True, check=True)\n    files = [Path(p) for p in result.stdout.strip().split(\"\\n\") if p]\n    print(f\"INFO: Found {len(files)} Python files to index.\")\n    return files\n"}, {"path": "assemblage\\code_search.py", "line": 22, "content": "\n\ndef _split_code_into_chunks(file_path: Path, content: str):\n    \"\"\"\n    Splits code into chunks based on class/function definitions.\n    \"\"\"\n    chunks = []\n    # Split by class/def, but keep the delimiter\n    split_points = re.split(r\"(^\\s*(?:def|class)\\s)\", content, flags=re.MULTILINE)\n\n    # The first element is the content before the first class/def (imports etc.)\n    # We can choose to index this or not. For now, we'll skip it.\n\n    # Re-combine the delimiter with the following code block\n    for i in range(1, len(split_points), 2):\n        chunk_header = split_points[i]\n        chunk_body = split_points[i + 1]\n        full_chunk = chunk_header + chunk_body\n\n        # Find line number of the chunk\n        # This is an approximation but good enough for this purpose\n        lines = content.splitlines()\n        line_num = -1\n        for idx, line in enumerate(lines):\n            if line.strip().startswith(chunk_header.strip()):\n                line_num = idx + 1\n                break\n\n        chunks.append({\"path\": str(file_path), \"line\": line_num, \"content\": full_chunk})\n\n    return chunks\n"}, {"path": "assemblage\\code_search.py", "line": 22, "content": "\n\ndef build_index():\n    \"\"\"\n    Builds the FAISS index and metadata for the entire codebase.\n    \"\"\"\n    print(\"INFO: Building code intelligence index...\")\n    INDEX_DIR.mkdir(exist_ok=True)\n\n    print(f\"INFO: Initializing sentence transformer model '{MODEL_NAME}'...\")\n    model = SentenceTransformer(MODEL_NAME)\n\n    all_files = _get_all_code_files()\n\n    all_chunks_content = []\n    all_chunks_metadata = []\n\n    print(\"INFO: Parsing files and splitting into code chunks...\")\n    for file_path in all_files:\n        try:\n            content = file_path.read_text(encoding=\"utf-8\")\n            chunks = _split_code_into_chunks(file_path, content)\n            for chunk in chunks:\n                all_chunks_content.append(chunk[\"content\"])\n                all_chunks_metadata.append(\n                    {\n                        \"path\": chunk[\"path\"],\n                        \"line\": chunk[\"line\"],\n                        \"content\": chunk[\"content\"],\n                    }\n                )\n        except Exception as e:\n            print(f\"WARNING: Could not process file {file_path}: {e}\")\n\n    if not all_chunks_content:\n        print(\"WARNING: No code chunks found to index.\")\n        return\n\n    print(f\"INFO: Generating embeddings for {len(all_chunks_content)} code chunks...\")\n    embeddings = model.encode(all_chunks_content, show_progress_bar=True)\n\n    dimension = embeddings.shape[1]\n    index = faiss.IndexFlatL2(dimension)\n    index.add(embeddings)\n\n    print(f\"INFO: Saving FAISS index to {INDEX_PATH}...\")\n    faiss.write_index(index, str(INDEX_PATH))\n\n    print(f\"INFO: Saving metadata to {METADATA_PATH}...\")\n    with open(METADATA_PATH, \"w\", encoding=\"utf-8\") as f:\n        json.dump(all_chunks_metadata, f)\n\n    print(\"INFO: Index build complete.\")\n"}, {"path": "assemblage\\code_search.py", "line": 22, "content": "\n\ndef search_index(query_text: str, top_k: int = 5):\n    \"\"\"\n    Searches the index for a given query.\n    \"\"\"\n    if not INDEX_PATH.exists() or not METADATA_PATH.exists():\n        raise FileNotFoundError(\n            \"Index not found. Please run 'control_plane index' first.\"\n        )\n\n    print(\"INFO: Loading code intelligence index...\")\n    index = faiss.read_index(str(INDEX_PATH))\n    with open(METADATA_PATH, \"r\", encoding=\"utf-8\") as f:\n        metadata = json.load(f)\n\n    print(f\"INFO: Initializing sentence transformer model '{MODEL_NAME}'...\")\n    model = SentenceTransformer(MODEL_NAME)\n\n    print(f\"INFO: Encoding query: '{query_text}'\")\n    query_vector = model.encode([query_text])\n\n    print(f\"INFO: Performing search for top {top_k} results...\")\n    distances, indices = index.search(query_vector, top_k)\n\n    results = []\n    for i, idx in enumerate(indices[0]):\n        if idx < len(metadata):\n            meta = metadata[idx]\n            results.append(\n                {\n                    \"score\": float(distances[0][i]),\n                    \"path\": meta[\"path\"],\n                    \"line\": meta[\"line\"],\n                    \"content\": meta[\"content\"],\n                }\n            )\n\n    return results\n"}, {"path": "assemblage\\commit_wrapper.py", "line": 19, "content": "\n\ndef run_command(command):\n    \"\"\"Runs a command and returns the result.\"\"\"\n    return subprocess.run(\n        command, capture_output=True, text=True, encoding=\"utf-8\", errors=\"replace\"\n    )\n"}, {"path": "assemblage\\commit_wrapper.py", "line": 19, "content": "\n\ndef main():\n    \"\"\"\n    Main entry point for the commit wrapper.\n    \"\"\"\n    parser = argparse.ArgumentParser(\n        description=\"A wrapper for git commit with a self-correction loop.\"\n    )\n    parser.add_argument(\"-m\", \"--message\", required=True, help=\"Commit message\")\n    args = parser.parse_args()\n\n    commit_command = [\"git\", \"commit\", \"-m\", args.message]\n\n    # --- First Attempt ---\n    print(f\"{YELLOW}--- Attempting commit... ---{NC}\")\n    result = run_command(commit_command)\n\n    if result.returncode == 0:\n        print(f\"{GREEN}\u2705 Commit successful on the first attempt.{NC}\")\n        print(result.stdout)\n        sys.exit(0)\n\n    # --- First Attempt Failed: Analyze and Potentially Retry ---\n    print(f\"{RED}--- Initial commit failed. Analyzing output... ---{NC}\")\n\n    combined_output = result.stdout + result.stderr\n    if \"- files were modified by this hook\" in combined_output:\n        print(\n            f\"{YELLOW}--- Fixable error detected. \"\n            f\"Staging fixes and re-trying... ---{NC}\"\n        )\n\n        # --- Second Attempt ---\n        run_command([\"git\", \"add\", \"-u\"])\n\n        print(f\"{YELLOW}--- Re-attempting commit... ---{NC}\")\n        second_result = run_command(commit_command)\n\n        if second_result.returncode == 0:\n            print(f\"{GREEN}\u2705 Self-correction successful! Commit has passed.{NC}\")\n            print(second_result.stdout)\n            sys.exit(0)\n        else:\n            print(\n                f\"{RED}\u274c Self-correction failed. The commit still fails after \"\n                f\"fixes.{NC}\"\n            )\n            print(second_result.stdout, file=sys.stderr)\n            print(second_result.stderr, file=sys.stderr)\n            sys.exit(1)\n    else:\n        print(\n            f\"{RED}\u274c Unfixable error detected. No self-correction will be \"\n            f\"attempted.{NC}\"\n        )\n        print(result.stdout, file=sys.stderr)\n        print(result.stderr, file=sys.stderr)\n        sys.exit(1)\n\n\nif __name__ == \"__main__\":\n    main()\n"}, {"path": "assemblage\\control_plane.py", "line": 32, "content": "\n\ndef _get_assemblage_status():\n    \"\"\"Gets the current version.\"\"\"\n    print(\"INFO: Getting Assemblage version...\")\n    version_file = Path(\"ASSEMBLAGE.version\")\n    status = \"\u2705 STABLE\"\n    status_json = \"STABLE\"\n    version = version_file.read_text().strip()\n    return {\"status\": status, \"status_json\": status_json, \"version\": version}\n"}, {"path": "assemblage\\control_plane.py", "line": 32, "content": "\n\ndef _get_conveyor_belt_metrics():\n    \"\"\"Counts items in the ideas, backlog, and specs directories.\"\"\"\n    print(\"INFO: Gathering conveyor belt metrics...\")\n    ideas_count = len(list(Path(\"ideas\").glob(\"*\")))\n    backlog_count = len(list(Path(\"backlog/items\").glob(\"*\")))\n    specs_count = len(list(Path(\"specs\").glob(\"*\")))\n    return {\"ideas\": ideas_count, \"backlog\": backlog_count, \"specs\": specs_count}\n"}, {"path": "assemblage\\control_plane.py", "line": 32, "content": "\n\ndef _get_recent_activity(limit=5):\n    \"\"\"Gets the most recent Git log entries.\"\"\"\n    print(\"INFO: Fetching recent activity from Git...\")\n    command = [\"git\", \"log\", f\"-n{limit}\", \"--pretty=format:%h|%s\"]\n    result = subprocess.run(command, capture_output=True, text=True, check=True)\n    log_entries = []\n    for line in result.stdout.strip().split(\"\\n\"):\n        if not line:\n            continue\n        hash_val, message = line.split(\"|\", 1)\n        log_entries.append({\"hash\": hash_val, \"message\": message})\n    return log_entries\n"}, {"path": "assemblage\\control_plane.py", "line": 32, "content": "\n\ndef _generate_dashboard():\n    \"\"\"Main function to orchestrate the dashboard generation.\"\"\"\n    print(\"INFO: Starting dashboard generation...\")\n    output_md = Path(\"STATUS.md\")\n    output_json = Path(\"status.json\")\n\n    try:\n        assemblage_health = _get_assemblage_status()\n        conveyor_belt = _get_conveyor_belt_metrics()\n        recent_activity = _get_recent_activity()\n\n        final_data = {\n            \"generated_at\": datetime.now(timezone.utc).isoformat(),\n            \"assemblage_health\": assemblage_health,\n            \"project_progress\": {\n                \"conveyor_belt\": conveyor_belt,\n                \"recent_activity\": recent_activity,\n            },\n        }\n\n        print(f\"INFO: Generating {output_json}...\")\n        with open(output_json, \"w\", encoding=\"utf-8\") as f:\n            json.dump(final_data, f, indent=2)\n\n        print(f\"INFO: Generating {output_md}...\")\n        md_content = f\"\"\"# Assemblage Status Report\n\n*Generated: {final_data['generated_at']}*\n\n---\n\n## \ud83c\udfdb\ufe0f Assemblage Health (\"The House\")\n\n- **Integrity Status:** {final_data['assemblage_health']['status']}\n- **Framework Version:** {final_data['assemblage_health']['version']}\n\n---\n\n## \ud83d\udecb\ufe0f Project Progress (\"The Furniture\")\n\n### \"Conveyor Belt\" Funnel\n- **\ud83d\udca1 Ideas:** {final_data['project_progress']['conveyor_belt']['ideas']}\n- **\ud83d\udccb Backlog:** {final_data['project_progress']['conveyor_belt']['backlog']}\n- **\ud83d\udcd0 Specs:** {final_data['project_progress']['conveyor_belt']['specs']}\n\n### Recent Activity\n\"\"\"\n        for entry in final_data[\"project_progress\"][\"recent_activity\"]:\n            md_content += f\"- `{entry['hash']}`: {entry['message']}\\n\"\n        output_md.write_text(md_content, encoding=\"utf-8\")\n\n        print(\"INFO: Dashboard generation complete.\")\n        print(f\"INFO: View the report: {output_md}\")\n        return True\n\n    except (FileNotFoundError, subprocess.CalledProcessError) as e:\n        print(f\"ERROR: A required file or command failed: {e}\", file=sys.stderr)\n        return False\n    except Exception as e:\n        print(f\"An unexpected error occurred: {e}\", file=sys.stderr)\n        return False\n\n\n# --- Private Logic for 'validate' command ---\n"}, {"path": "assemblage\\control_plane.py", "line": 32, "content": "\n\ndef _log_section(name):\n    print(f\"\\n--- CHECK: {name} ---\")\n"}, {"path": "assemblage\\control_plane.py", "line": 32, "content": "\n\ndef _log_success(message):\n    print(f\"{GREEN}[PASS] {message}{NC}\")\n"}, {"path": "assemblage\\control_plane.py", "line": 32, "content": "\n\ndef _log_failure(message):\n    print(f\"{RED}[FAIL] {message}{NC}\", file=sys.stderr)\n"}, {"path": "assemblage\\control_plane.py", "line": 32, "content": "\n\ndef _check_git_integrity():\n    _log_section(\"GIT-INTEGRITY\")\n    print(\"INFO: Checking for uncommitted changes...\")\n    paths_to_check = [\n        \"config/\",\n        \"guides/\",\n        \".githooks/\",\n        \"ASSEMBLAGE.version\",\n        \"CHANGELOG.md\",\n        \"FOUNDATION.md\",\n        \"README.md\",\n        \"GEMINI.md\",\n        \"CLAUDE.md\",\n        \"decisions/\",\n    ]\n    cmd = [\"git\", \"status\", \"--porcelain\"] + paths_to_check\n    result = subprocess.run(cmd, capture_output=True, text=True)\n    if result.stdout:\n        _log_failure(\"Git Integrity Check FAILED.\")\n        print(\"The following 'house' files are modified or untracked:\", file=sys.stderr)\n        print(result.stdout, file=sys.stderr)\n        return False\n    _log_success(\"Git Integrity Check PASSED.\")\n    return True\n"}, {"path": "assemblage\\control_plane.py", "line": 32, "content": "\n\ndef _check_version_alignment():\n    _log_section(\"VERSION-ALIGNMENT\")\n    print(\"INFO: Checking version alignment...\")\n    version_file = Path(\"ASSEMBLAGE.version\")\n    changelog_file = Path(\"CHANGELOG.md\")\n    if not version_file.is_file() or not changelog_file.is_file():\n        _log_failure(\"Version file or changelog not found.\")\n        return False\n    current_version = version_file.read_text().strip()\n    changelog_content = changelog_file.read_text()\n    match = re.search(r\"##\\s*\\[(\\d+\\.\\d+\\.\\d+)\\]\", changelog_content)\n    if not match:\n        _log_failure(\"Could not find any version in CHANGELOG.md.\")\n        return False\n    latest_changelog_version = match.group(1)\n    if current_version != latest_changelog_version:\n        _log_failure(\"Version Alignment Check FAILED.\")\n        print(f\"  '{version_file}' reports:   {current_version}\", file=sys.stderr)\n        print(\n            f\"  '{changelog_file}' reports: {latest_changelog_version}\",\n            file=sys.stderr,\n        )\n        return False\n    _log_success(\n        f\"Version Alignment Check PASSED. Version '{current_version}' is aligned.\"\n    )\n    return True\n"}, {"path": "assemblage\\control_plane.py", "line": 32, "content": "\n\ndef _find_paths_in_yaml(data):\n    if isinstance(data, dict):\n        for value in data.values():\n            yield from _find_paths_in_yaml(value)\n    elif isinstance(data, list):\n        for item in data:\n            yield from _find_paths_in_yaml(item)\n    elif isinstance(data, str) and (\n        (\".\" in data and \"/\" in data) or data.endswith((\".md\", \".sh\", \".py\", \".yml\"))\n    ):\n        yield data\n"}, {"path": "assemblage\\control_plane.py", "line": 32, "content": "\n\ndef _check_wiring_integrity():\n    _log_section(\"WIRING-INTEGRITY\")\n    print(\"INFO: Checking for 'dead wires' in configuration...\")\n    all_paths_valid = True\n    config_files_to_check = [\"config/workbenches.yml\", \"config/specialists.yml\"]\n    for config_file in config_files_to_check:\n        if not Path(config_file).is_file():\n            _log_failure(f\"Configuration file not found: {config_file}\")\n            all_paths_valid = False\n            continue\n        with open(config_file, \"r\") as f:\n            data = yaml.safe_load(f)\n        for path in _find_paths_in_yaml(data):\n            if \"{{\" in path:\n                continue\n            if not Path(path).exists():\n                _log_failure(\n                    f\"DEAD WIRE DETECTED in '{config_file}': \"\n                    f\"Path '{path}' does not exist.\"\n                )\n                all_paths_valid = False\n    if all_paths_valid:\n        _log_success(\"Wiring Integrity Check PASSED.\")\n    return all_paths_valid\n"}, {"path": "assemblage\\control_plane.py", "line": 32, "content": "\n\ndef _validate_assemblage():\n    \"\"\"Runs all validation checks and returns True if all pass, otherwise False.\"\"\"\n    print(f\"{BLUE}--- Running MASTER Assemblage Integrity Validation ---{NC}\")\n    checks = [_check_git_integrity, _check_version_alignment, _check_wiring_integrity]\n    results = [check() for check in checks]\n    print(\"\\n---\")\n    if all(results):\n        _log_success(\"\u2705 MASTER Assemblage Integrity Protocol PASSED.\")\n        return True\n    else:\n        _log_failure(\"\u274c MASTER Assemblage Integrity Protocol FAILED.\")\n        return False\n\n\n# --- Private Logic for 'create_specialist' command ---\n"}, {"path": "assemblage\\control_plane.py", "line": 32, "content": "\n\ndef _prompt_user(prompt_text):\n    \"\"\"Prints a prompt and returns sanitized user input.\"\"\"\n    print(f\"\\n{BLUE}[PROMPT] {prompt_text}{NC}\", file=sys.stderr)\n    return sys.stdin.readline().strip()\n"}, {"path": "assemblage\\control_plane.py", "line": 32, "content": "\n\ndef _create_new_specialist():\n    \"\"\"Main function to orchestrate the specialist creation process.\"\"\"\n    print(f\"{GREEN}--- Starting create-new-specialist Utility ---{NC}\")\n    registry_file = Path(\"config/specialists.yml\")\n    if not registry_file.is_file():\n        print(\n            f\"{RED}ERROR: Specialist Registry not found at '{registry_file}'!{NC}\",\n            file=sys.stderr,\n        )\n        return False\n    specialist_id = _prompt_user(\n        \"Enter the unique ID for the new specialist (e.g., 'mcp_architect'):\"\n    )\n    if not specialist_id:\n        print(f\"{RED}ERROR: Specialist ID cannot be empty.{NC}\", file=sys.stderr)\n        return False\n    with open(registry_file, \"r\") as f:\n        existing_specialists = yaml.safe_load(f) or {}\n    if specialist_id in existing_specialists.get(\"specialists\", {}):\n        print(\n            f\"{RED}ERROR: Specialist ID '{specialist_id}' already exists.{NC}\",\n            file=sys.stderr,\n        )\n        return False\n    description = _prompt_user(\n        f\"Enter the one-sentence description for '{specialist_id}':\"\n    )\n    output_anchor = _prompt_user(\n        \"Enter the output_anchor path (e.g., 'knowledge/research/report.md'):\"\n    )\n    print(\n        f\"\\n{BLUE}[PROMPT] Enter the multi-line 'guide_prompt' for this \"\n        f\"specialist.{NC}\",\n        file=sys.stderr,\n    )\n    print(\n        f\"{BLUE}(Type 'EOF' on a new line when you are finished){NC}\", file=sys.stderr\n    )\n    guide_prompt_lines = [line for line in sys.stdin]\n    guide_prompt = \"\".join(guide_prompt_lines).replace(\"EOF\\n\", \"\")\n    if \"specialists\" not in existing_specialists:\n        existing_specialists[\"specialists\"] = {}\n    existing_specialists[\"specialists\"][specialist_id] = {\n        \"description\": description,\n        \"output_anchor\": output_anchor,\n        \"guide_prompt\": guide_prompt,\n    }\n    print(f\"\\n{GREEN}INFO: Registering new specialist '{specialist_id}'...{NC}\")\n    with open(registry_file, \"w\") as f:\n        yaml.dump(\n            existing_specialists, f, indent=2, default_flow_style=False, sort_keys=False\n        )\n    print(\n        f\"\\n{GREEN}\u2705 Successfully provisioned new Cognitive Specialist: \"\n        f\"'{specialist_id}'.{NC}\"\n    )\n    print(\n        f\"{BLUE}Nudge: This is an 'Assemblage' change. You MUST now follow the \"\n        f\"change protocol to commit it.{NC}\"\n    )\n    return True\n\n\n# --- Private Logic for 'nudge' command ---\n"}, {"path": "assemblage\\control_plane.py", "line": 32, "content": "\n\ndef _deliver_nudge(nudge_id, current_workbench):\n    \"\"\"Checks firewall rules and delivers a nudge if available.\"\"\"\n    workbench_config = Path(\"config/workbenches.yml\")\n    nudge_library = Path(\"config/nudges.yml\")\n    try:\n        with open(workbench_config, \"r\") as f:\n            workbenches_data = yaml.safe_load(f)\n        with open(nudge_library, \"r\") as f:\n            nudges_data = yaml.safe_load(f)\n    except FileNotFoundError as e:\n        print(f\"{RED}ERROR: Configuration file not found: {e}{NC}\", file=sys.stderr)\n        return False\n    try:\n        available_nudges = workbenches_data[\"workbenches\"][current_workbench][\n            \"available_nudges\"\n        ]\n    except KeyError:\n        print(\n            f\"{RED}ERROR: Workbench '{current_workbench}' not found in \"\n            f\"{workbench_config}{NC}\",\n            file=sys.stderr,\n        )\n        return False\n    if nudge_id not in available_nudges:\n        print(\n            f\"{RED}[NUDGE FAIL] Nudge '{nudge_id}' is NOT available for the \"\n            f\"'{current_workbench}' Workbench.{NC}\",\n            file=sys.stderr,\n        )\n        print(\n            f\"{YELLOW}This is a 'How' (Platform) Guardrail to prevent \"\n            f\"'interference'.{NC}\",\n            file=sys.stderr,\n        )\n        return False\n    nudge_text = nudges_data.get(\"nudges\", {}).get(nudge_id)\n    if not nudge_text:\n        print(\n            f\"{RED}ERROR: Nudge ID '{nudge_id}' does not exist in the Nudge \"\n            f\"Library.{NC}\",\n            file=sys.stderr,\n        )\n        return False\n    print(f\"\\n{CYAN}\ud83d\udca1 NUDGE ({nudge_id}):{NC}\")\n    print(f\"{CYAN}---------------------------------{NC}\")\n    print(nudge_text)\n    print(f\"{CYAN}---------------------------------{NC}\\n\")\n    return True\n\n\n# --- Public Command Handlers ---\n"}, {"path": "assemblage\\control_plane.py", "line": 32, "content": "\n\ndef observe_command(args):\n    \"\"\"Handler for the 'observe' command.\"\"\"\n    print(\"--- Control Plane: Executing 'observe' ---\")\n    if _generate_dashboard():\n        sys.exit(0)\n    else:\n        sys.exit(1)\n"}, {"path": "assemblage\\control_plane.py", "line": 32, "content": "\n\ndef validate_command(args):\n    \"\"\"Handler for the 'validate' command.\"\"\"\n    print(\"--- Control Plane: Executing 'validate' ---\")\n    if _validate_assemblage():\n        sys.exit(0)\n    else:\n        sys.exit(1)\n"}, {"path": "assemblage\\control_plane.py", "line": 32, "content": "\n\ndef create_specialist_command(args):\n    \"\"\"Handler for the 'create_specialist' command.\"\"\"\n    print(\"--- Control Plane: Launching 'create_specialist' ---\")\n    if _create_new_specialist():\n        sys.exit(0)\n    else:\n        sys.exit(1)\n"}, {"path": "assemblage\\control_plane.py", "line": 32, "content": "\n\ndef nudge_command(args):\n    \"\"\"Handler for the 'nudge' command.\"\"\"\n    print(\"--- Control Plane: Executing 'nudge' ---\")\n    if _deliver_nudge(args.nudge_id, args.current_workbench):\n        sys.exit(0)\n    else:\n        sys.exit(1)\n"}, {"path": "assemblage\\control_plane.py", "line": 32, "content": "\n\ndef index_command(args):\n    \"\"\"Handler for the 'index' command.\"\"\"\n    print(\"--- Control Plane: Executing 'index' ---\")\n    try:\n        code_search.build_index()\n        sys.exit(0)\n    except Exception as e:\n        print(f\"ERROR: Indexing failed: {e}\", file=sys.stderr)\n        sys.exit(1)\n"}, {"path": "assemblage\\control_plane.py", "line": 32, "content": "\n\ndef query_command(args):\n    \"\"\"Handler for the 'query' command.\"\"\"\n    print(\"--- Control Plane: Executing 'query' ---\")\n    try:\n        results = code_search.search_index(args.query)\n        # Format and print results as per ADR-009\n        print(f'\\n## Code Query Results for: \"{args.query}\"\\n')\n        if not results:\n            print(\"No relevant code snippets found.\")\n            sys.exit(0)\n\n        print(f\"**Top {len(results)} Results:**\\n\")\n        for i, res in enumerate(results):\n            print(\"---\")\n            print(f\"**{i+1}. File:** `{res['path']}`\")\n            print(f\"**Lines:** {res['line']}\")\n            print(f\"**Confidence Score:** {res['score']:.2f}\\n\")\n            print(f\"```python\\n{res['content']}\\n```\")\n        print(\"---\\n\")\n        sys.exit(0)\n    except Exception as e:\n        print(f\"ERROR: Query failed: {e}\", file=sys.stderr)\n        sys.exit(1)\n"}, {"path": "assemblage\\control_plane.py", "line": 32, "content": "\n\ndef status_command(args):\n    \"\"\"Handler for the 'status' command.\"\"\"\n    if args.index:\n        print(\"--- Control Plane: Checking 'index' status ---\")\n        if code_search.INDEX_PATH.exists():\n            mod_time = datetime.fromtimestamp(\n                code_search.INDEX_PATH.stat().st_mtime\n            ).isoformat()\n            with open(code_search.METADATA_PATH, \"r\") as f:\n                item_count = len(json.load(f))\n            print(\"\u2705 Index found.\")\n            print(f\"   - Last built: {mod_time}\")\n            print(f\"   - Indexed items: {item_count}\")\n        else:\n            print(\"\u274c Index not found. Run 'control_plane index' to build it.\")\n        sys.exit(0)\n    else:\n        print(\"Please specify a status to check (e.g., --index).\")\n        sys.exit(1)\n\n\n# --- Main Entry Point ---\n"}, {"path": "assemblage\\control_plane.py", "line": 32, "content": "\n\ndef main():\n    \"\"\"\n    Main entry point for the Assemblage Control Plane.\n    Parses commands and dispatches them to the appropriate handlers.\n    \"\"\"\n    parser = argparse.ArgumentParser(\n        description=(\n            \"Assemblage Control Plane: Abstract interface for agent-tool interaction.\"\n        )\n    )\n    subparsers = parser.add_subparsers(dest=\"command\", required=True)\n\n    parser_observe = subparsers.add_parser(\n        \"observe\",\n        help=\"Observe the state of the Assemblage and generate a status dashboard.\",\n    )\n    parser_observe.set_defaults(func=observe_command)\n\n    parser_validate = subparsers.add_parser(\n        \"validate\", help=\"Run a full integrity check of the Assemblage.\"\n    )\n    parser_validate.set_defaults(func=validate_command)\n\n    parser_create_specialist = subparsers.add_parser(\n        \"create_specialist\",\n        help=\"Launch the interactive wizard to create a new Cognitive Specialist.\",\n    )\n    parser_create_specialist.set_defaults(func=create_specialist_command)\n\n    parser_nudge = subparsers.add_parser(\"nudge\", help=\"Deliver a behavioral nudge.\")\n    parser_nudge.add_argument(\"nudge_id\", help=\"The ID of the nudge to deliver.\")\n    parser_nudge.add_argument(\"current_workbench\", help=\"The active workbench.\")\n    parser_nudge.set_defaults(func=nudge_command)\n\n    # Code Query System commands\n    parser_index = subparsers.add_parser(\n        \"index\", help=\"Build the code intelligence index.\"\n    )\n    parser_index.set_defaults(func=index_command)\n\n    parser_query = subparsers.add_parser(\n        \"query\", help=\"Perform a semantic query on the codebase.\"\n    )\n    parser_query.add_argument(\"query\", help=\"The natural language query string.\")\n    parser_query.set_defaults(func=query_command)\n\n    parser_status = subparsers.add_parser(\n        \"status\", help=\"Check the status of a system.\"\n    )\n    parser_status.add_argument(\n        \"--index\", action=\"store_true\", help=\"Check the status of the code index.\"\n    )\n    parser_status.set_defaults(func=status_command)\n\n    args = parser.parse_args()\n    args.func(args)\n\n\nif __name__ == \"__main__\":\n    main()\n"}, {"path": "tests\\test_code_search.py", "line": 15, "content": "def mock_codebase(tmp_path):\n    \"\"\"Creates a temporary directory with mock python files.\"\"\"\n    p = tmp_path / \"src\"\n    p.mkdir()\n    file1 = p / \"file1.py\"\n    file1.write_text(\n        '\"\"\"This is a docstring.\"\"\"\\n\\n'\n        \"import os\\n\\n\"\n        \"class MyClass:\\n\"\n        \"    pass\\n\\n\"\n        \"def function_for_adding(a, b):\\n\"\n        '    \"\"\"This function adds two numbers.\"\"\"\\n'\n        \"\"\n        \"    return a + b\\n\"\n    )\n\n    file2 = p / \"file2.py\"\n    file2.write_text(\n        \"def function_for_subtracting(a, b):\\n\"\n        '    \"\"\"This function subtracts two numbers.\"\"\"\\n'\n        \"\"\n        \"    return a - b\\n\"\n    )\n\n    # Also create a gitignore in the root\n    gitignore = tmp_path / \".gitignore\"\n    gitignore.write_text(\"*.txt\\n.venv/\\n\")\n\n    return tmp_path\n"}, {"path": "tests\\test_code_search.py", "line": 15, "content": "\n\ndef test_build_index(mock_codebase, monkeypatch):\n    \"\"\"\n    Tests that the index is built correctly.\n    \"\"\"\n\n    # We need to patch _get_all_code_files to work with our temp dir\n"}, {"path": "tests\\test_code_search.py", "line": 15, "content": "    def mock_get_files():\n        return list(mock_codebase.glob(\"**/*.py\"))\n\n    monkeypatch.setattr(code_search, \"_get_all_code_files\", mock_get_files)\n\n    # We also need to patch the location of the index\n    monkeypatch.setattr(code_search, \"INDEX_DIR\", mock_codebase / \".assemblage_cache\")\n    monkeypatch.setattr(\n        code_search, \"INDEX_PATH\", mock_codebase / \".assemblage_cache/code_index.faiss\"\n    )\n    monkeypatch.setattr(\n        code_search,\n        \"METADATA_PATH\",\n        mock_codebase / \".assemblage_cache/code_index_meta.json\",\n    )\n\n    code_search.build_index()\n\n    assert (mock_codebase / \".assemblage_cache/code_index.faiss\").exists()\n    meta_path = mock_codebase / \".assemblage_cache/code_index_meta.json\"\n    assert meta_path.exists()\n\n    with open(meta_path, \"r\") as f:\n        metadata = json.load(f)\n\n    # Should find 3 chunks: MyClass, function_for_adding, function_for_subtracting\n    assert len(metadata) == 3\n    assert metadata[1][\"path\"] == str(mock_codebase / \"src/file1.py\")\n"}, {"path": "tests\\test_code_search.py", "line": 15, "content": "\n\ndef test_search_index(mock_codebase, monkeypatch):\n    \"\"\"\n    Tests that the search function returns relevant results.\n    \"\"\"\n\n    # Set up the mock environment and build the index first\n"}, {"path": "tests\\test_code_search.py", "line": 15, "content": "    def mock_get_files():\n        return list(mock_codebase.glob(\"**/*.py\"))\n\n    monkeypatch.setattr(code_search, \"_get_all_code_files\", mock_get_files)\n    index_dir = mock_codebase / \".assemblage_cache\"\n    monkeypatch.setattr(code_search, \"INDEX_DIR\", index_dir)\n    monkeypatch.setattr(code_search, \"INDEX_PATH\", index_dir / \"code_index.faiss\")\n    monkeypatch.setattr(\n        code_search, \"METADATA_PATH\", index_dir / \"code_index_meta.json\"\n    )\n\n    code_search.build_index()\n\n    # Now, perform the search\n    results = code_search.search_index(\"logic for subtraction\")\n\n    assert len(results) > 0\n    top_result = results[0]\n\n    assert top_result[\"path\"] == str(mock_codebase / \"src/file2.py\")\n    assert top_result[\"line\"] > 0\n    assert \"return a - b\" in top_result[\"content\"]\n"}, {"path": "tests\\test_commit_wrapper.py", "line": 16, "content": "def test_success_on_first_try(mock_run):\n    \"\"\"\n    Tests that the script exits 0 if the first commit succeeds.\n    \"\"\"\n    mock_run.return_value = MagicMock(returncode=0, stdout=\"Success!\")\n    with patch.object(sys, \"argv\", [\"commit_wrapper.py\", \"-m\", \"test commit\"]):\n        with pytest.raises(SystemExit) as e:\n            commit_wrapper.main()\n        assert e.value.code == 0\n\n    assert mock_run.call_count == 1\n    mock_run.assert_called_with(\n        [\"git\", \"commit\", \"-m\", \"test commit\"], capture_output=True, text=True\n    )\n\n\n@patch(\"assemblage.commit_wrapper.subprocess.run\")\n"}, {"path": "tests\\test_commit_wrapper.py", "line": 16, "content": "def test_successful_self_correction(mock_run):\n    \"\"\"\n    Tests the full self-correction happy path.\n    \"\"\"\n    # Simulate the sequence of subprocess calls\n    mock_run.side_effect = [\n        # 1. First commit fails with fixable error\n        MagicMock(returncode=1, stdout=\"- files were modified by this hook\", stderr=\"\"),\n        # 2. 'git add -u' succeeds\n        MagicMock(returncode=0),\n        # 3. Second commit succeeds\n        MagicMock(returncode=0, stdout=\"Success on second try!\"),\n    ]\n\n    with patch.object(sys, \"argv\", [\"commit_wrapper.py\", \"-m\", \"test commit\"]):\n        with pytest.raises(SystemExit) as e:\n            commit_wrapper.main()\n        assert e.value.code == 0\n\n    assert mock_run.call_count == 3\n\n\n@patch(\"assemblage.commit_wrapper.subprocess.run\")\n"}, {"path": "tests\\test_commit_wrapper.py", "line": 16, "content": "def test_failure_on_unfixable_error(mock_run):\n    \"\"\"\n    Tests that the script fails if the error is not fixable.\n    \"\"\"\n    mock_run.return_value = MagicMock(\n        returncode=1, stdout=\"A real error\", stderr=\"Something broke\"\n    )\n    with patch.object(sys, \"argv\", [\"commit_wrapper.py\", \"-m\", \"test commit\"]):\n        with pytest.raises(SystemExit) as e:\n            commit_wrapper.main()\n        assert e.value.code == 1\n\n    assert mock_run.call_count == 1\n\n\n@patch(\"assemblage.commit_wrapper.subprocess.run\")\n"}, {"path": "tests\\test_commit_wrapper.py", "line": 16, "content": "def test_failure_on_second_attempt(mock_run):\n    \"\"\"\n    Tests that the script fails if the second commit attempt also fails.\n    \"\"\"\n    mock_run.side_effect = [\n        MagicMock(returncode=1, stdout=\"- files were modified by this hook\", stderr=\"\"),\n        MagicMock(returncode=0),\n        MagicMock(returncode=1, stderr=\"Still broken\"),\n    ]\n\n    with patch.object(sys, \"argv\", [\"commit_wrapper.py\", \"-m\", \"test commit\"]):\n        with pytest.raises(SystemExit) as e:\n            commit_wrapper.main()\n        assert e.value.code == 1\n\n    assert mock_run.call_count == 3\n"}, {"path": "tests\\test_control_plane.py", "line": 15, "content": "\n\ndef test_observe_command_success(monkeypatch):\n    \"\"\"\n    Tests that the 'observe' command successfully calls the internal logic.\n    \"\"\"\n    mock_generate = MagicMock(return_value=True)\n    monkeypatch.setattr(control_plane, \"_generate_dashboard\", mock_generate)\n    monkeypatch.setattr(sys, \"argv\", [\"control_plane.py\", \"observe\"])\n\n    with pytest.raises(SystemExit) as e:\n        control_plane.main()\n\n    assert e.value.code == 0\n    mock_generate.assert_called_once()\n"}, {"path": "tests\\test_control_plane.py", "line": 15, "content": "\n\ndef test_invalid_command(capsys):\n    \"\"\"\n    Tests that an invalid command exits with an error.\n    \"\"\"\n    with patch(\"sys.argv\", [\"control_plane.py\", \"invalid_command\"]):\n        with pytest.raises(SystemExit) as e:\n            control_plane.main()\n\n        assert e.value.code != 0\n        captured = capsys.readouterr()\n        assert \"usage: control_plane.py\" in captured.err\n        assert \"invalid choice: 'invalid_command'\" in captured.err\n"}, {"path": "tests\\test_control_plane.py", "line": 15, "content": "\n\ndef test_validate_command_success(monkeypatch):\n    \"\"\"\n    Tests that the 'validate' command exits with 0 on success.\n    \"\"\"\n    mock_validate = MagicMock(return_value=True)\n    monkeypatch.setattr(control_plane, \"_validate_assemblage\", mock_validate)\n    monkeypatch.setattr(sys, \"argv\", [\"control_plane.py\", \"validate\"])\n\n    with pytest.raises(SystemExit) as e:\n        control_plane.main()\n\n    assert e.value.code == 0\n    mock_validate.assert_called_once()\n"}, {"path": "tests\\test_control_plane.py", "line": 15, "content": "\n\ndef test_validate_command_failure(monkeypatch):\n    \"\"\"\n    Tests that the 'validate' command exits with 1 on failure.\n    \"\"\"\n    mock_validate = MagicMock(return_value=False)\n    monkeypatch.setattr(control_plane, \"_validate_assemblage\", mock_validate)\n    monkeypatch.setattr(sys, \"argv\", [\"control_plane.py\", \"validate\"])\n\n    with pytest.raises(SystemExit) as e:\n        control_plane.main()\n\n    assert e.value.code == 1\n    mock_validate.assert_called_once()\n"}, {"path": "tests\\test_control_plane.py", "line": 15, "content": "\n\ndef test_create_specialist_command_success(monkeypatch):\n    \"\"\"\n    Tests that the 'create_specialist' command exits with 0 on success.\n    \"\"\"\n    mock_create = MagicMock(return_value=True)\n    monkeypatch.setattr(control_plane, \"_create_new_specialist\", mock_create)\n    monkeypatch.setattr(sys, \"argv\", [\"control_plane.py\", \"create_specialist\"])\n\n    with pytest.raises(SystemExit) as e:\n        control_plane.main()\n\n    assert e.value.code == 0\n"}, {"path": "tests\\test_control_plane.py", "line": 15, "content": "\n\ndef test_nudge_command_success(monkeypatch):\n    \"\"\"\n    Tests that the 'nudge' command exits with 0 on success.\n    \"\"\"\n    mock_nudge = MagicMock(return_value=True)\n    monkeypatch.setattr(control_plane, \"_deliver_nudge\", mock_nudge)\n    monkeypatch.setattr(\n        sys, \"argv\", [\"control_plane.py\", \"nudge\", \"some_nudge\", \"some_workbench\"]\n    )\n\n    with pytest.raises(SystemExit) as e:\n        control_plane.main()\n\n    assert e.value.code == 0\n    mock_nudge.assert_called_once_with(\"some_nudge\", \"some_workbench\")\n"}, {"path": "tests\\test_control_plane.py", "line": 15, "content": "\n\ndef test_nudge_command_failure(monkeypatch):\n    \"\"\"\n    Tests that the 'nudge' command exits with 1 on failure.\n    \"\"\"\n    mock_nudge = MagicMock(return_value=False)\n    monkeypatch.setattr(control_plane, \"_deliver_nudge\", mock_nudge)\n    monkeypatch.setattr(\n        sys, \"argv\", [\"control_plane.py\", \"nudge\", \"blocked_nudge\", \"builder\"]\n    )\n\n    with pytest.raises(SystemExit) as e:\n        control_plane.main()\n\n    assert e.value.code == 1\n    mock_nudge.assert_called_once_with(\"blocked_nudge\", \"builder\")\n"}, {"path": "tests\\tools\\test_pre_commit_hook.py", "line": 11, "content": "\ndef test_hook_success_on_clean_code():\n    \"\"\"\n    Tests that the script exits with 0 when ruff finds no errors.\n    \"\"\"\n    with patch(\"subprocess.run\") as mock_run:\n        # Mock a successful run (returncode 0)\n        mock_process = MagicMock()\n        mock_process.returncode = 0\n        mock_run.return_value = mock_process\n        \n        with pytest.raises(SystemExit) as e:\n            pre_commit_hook.main()\n        \n        assert e.type == SystemExit\n        assert e.value.code == 0\n"}, {"path": "tests\\tools\\test_pre_commit_hook.py", "line": 11, "content": "\ndef test_hook_failure_on_lint_errors():\n    \"\"\"\n    Tests that the script exits with 1 when ruff finds errors.\n    \"\"\"\n    with patch(\"subprocess.run\") as mock_run:\n        # Mock a failed run (returncode 1)\n        mock_process = MagicMock()\n        mock_process.returncode = 1\n        mock_run.return_value = mock_process\n        \n        with pytest.raises(SystemExit) as e:\n            pre_commit_hook.main()\n            \n        assert e.type == SystemExit\n        assert e.value.code == 1\n"}, {"path": "tests\\tools\\test_pre_commit_hook.py", "line": 11, "content": "\ndef test_hook_handles_file_not_found():\n    \"\"\"\n    Tests that the script exits with 1 if 'ruff' command is not found.\n    \"\"\"\n    with patch(\"subprocess.run\", side_effect=FileNotFoundError) as mock_run:\n        with pytest.raises(SystemExit) as e:\n            pre_commit_hook.main()\n            \n        assert e.type == SystemExit\n        assert e.value.code == 1\n"}]
